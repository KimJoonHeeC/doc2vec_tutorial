{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "class seq2seq:\n",
    "    logits = None\n",
    "    outputs = None\n",
    "    cost = None\n",
    "    train_op = None\n",
    "    \n",
    "    def __init__(self, vocab_size, n_hidden=128, n_layers=3):\n",
    "        self.learning_late = 0.0005\n",
    "        \n",
    "        self.vocab_size = vocab_size\n",
    "        self.n_hidden = n_hidden\n",
    "        self.n_layers = n_layers\n",
    "        \n",
    "        self.enc_input = tf.placeholder(tf.float32, [None, None, self.vocab_size])\n",
    "        self.dec_input = tf.placeholder(tf.float32, [None, None, self.vocab_size])\n",
    "        self.targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from dialog import Dialog\n",
    "from config import FLAGS\n",
    "\n",
    "dialog = Dialog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "a = dialog.load_vocab(FLAGS.voc_path)\n",
    "b = dialog.load_examples(FLAGS.data_path)\n",
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dialog.load_vocab(FLAGS.voc_path)\n",
    "dialog.load_examples(FLAGS.data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tokenizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-3819f940d22c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtokenizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'tokenizer' is not defined"
     ]
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "    _PAD_ = '_PAD_'  # padding symbol\n",
    "    _STA_ = '_STA_'  # start symbol of decode input\n",
    "    _EOS_ = '_EOS_'  # end symbol of decode input-output\n",
    "    _UNK_ = '_UNK_'  # symbol undefined word in dict\n",
    "\n",
    "    _PAD_ID_ = 0\n",
    "    _STA_ID_ = 1\n",
    "    _EOS_ID_ = 2\n",
    "    _UNK_ID_ = 3\n",
    "    _PRE_DEFINED_ = [_PAD_ID_, _STA_ID_, _EOS_ID_, _UNK_ID_]\n",
    "    \n",
    "    def load_examples(data_path):\n",
    "        examples = []\n",
    "\n",
    "        with open(data_path, 'r', encoding='utf-8') as content_file:\n",
    "            for line in content_file:\n",
    "                sentence = line.strip()\n",
    "                tokens = tokenizer(line.strip())\n",
    "                #ids = tokens_to_ids(tokens)\n",
    "                examples.append(sentence)\n",
    "        return examples\n",
    "\n",
    "    def tokenizer(sentence):\n",
    "        # divided by blank, and sampling special letters\n",
    "        words = []\n",
    "        _TOKEN_RE_ = re.compile(\"([.,!?\\\"':;)(])\")\n",
    "\n",
    "        for fragment in sentence.strip().split():\n",
    "            words.extend(_TOKEN_RE_.split(fragment))\n",
    "        return words\n",
    "\n",
    "    def load_vocab(vocab_path):\n",
    "        vocab_list = _PRE_DEFINED_ + []\n",
    "\n",
    "        with open(vocab_path, 'r', encoding='utf-8') as vocab_file:\n",
    "            for line in vocab_file:\n",
    "                vocab_list.append(line.strip())\n",
    "\n",
    "        # {'_PAD_': 0, '_STA_': 1, '_EOS_': 2, '_UNK_': 3, 'Hello': 4, 'World': 5, ...}\n",
    "        vocab_dict = {n: i for i, n in enumerate(vocab_list)}\n",
    "        vocab_size = len(vocab_list)\n",
    "        \n",
    "        return vocab_list\n",
    "\n",
    "    def tokens_to_ids(tokens):\n",
    "        ids = []\n",
    "\n",
    "        for t in tokens:\n",
    "            if t in vocab_dict:\n",
    "                ids.append(vocab_dict[t])\n",
    "            else:\n",
    "                ids.append(_UNK_ID_)\n",
    "\n",
    "        return ids\n",
    "\n",
    "    def ids_to_tokens(ids):\n",
    "        tokens = []\n",
    "\n",
    "        for i in ids:\n",
    "            tokens.append(vocab_list[i])\n",
    "\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "voc_path = 'data/chat.voc'\n",
    "data_path = 'data/chat.log'\n",
    "\n",
    "vocab_list = []\n",
    "vocab_dict = {}\n",
    "vocab_size = 0\n",
    "examples = []\n",
    "\n",
    "_index_in_epoch = 0\n",
    "\n",
    "examples = load_examples(data_path)\n",
    "vocab = load_vocab(voc_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " '목요일은',\n",
       " '대단하군',\n",
       " '사냥꾼이',\n",
       " '마을',\n",
       " '잘',\n",
       " '거야',\n",
       " '싶다면',\n",
       " '것은',\n",
       " '비밀은',\n",
       " '그러구',\n",
       " '울려고',\n",
       " '생활은',\n",
       " '게',\n",
       " '아니',\n",
       " '것이',\n",
       " '그럼',\n",
       " '모두',\n",
       " '그럴',\n",
       " '위엔',\n",
       " '넌',\n",
       " '책임이',\n",
       " '의례가',\n",
       " '예쁘구나',\n",
       " '보면',\n",
       " '사람들은',\n",
       " '춤을',\n",
       " '사람들을',\n",
       " '있으니까',\n",
       " '그래서',\n",
       " '와서',\n",
       " '미안해',\n",
       " '거지',\n",
       " '너를',\n",
       " '목요일엔',\n",
       " '네',\n",
       " '햇빛처럼',\n",
       " '사과나무',\n",
       " '없지',\n",
       " '수',\n",
       " '장미한테',\n",
       " '닭은',\n",
       " '것에',\n",
       " '있어야',\n",
       " '신나는',\n",
       " '지겨워',\n",
       " '눈에',\n",
       " '시간과',\n",
       " '길들이면',\n",
       " '갖고',\n",
       " '정말',\n",
       " '어떻게',\n",
       " '관계가',\n",
       " '그런데',\n",
       " '참을성이',\n",
       " '아',\n",
       " '그들은',\n",
       " '안',\n",
       " '줘',\n",
       " '길들여',\n",
       " '?',\n",
       " '다른',\n",
       " '닭을',\n",
       " '울',\n",
       " '친구를',\n",
       " '뜻이야',\n",
       " '그래',\n",
       " '참',\n",
       " '만드는',\n",
       " '것',\n",
       " '진실을',\n",
       " '무얼',\n",
       " '있지',\n",
       " '않는다',\n",
       " '날',\n",
       " '생긴다는',\n",
       " '온갖',\n",
       " '친구가',\n",
       " '지구',\n",
       " '이',\n",
       " '나를',\n",
       " '내',\n",
       " '해',\n",
       " '난',\n",
       " '밀밭을',\n",
       " '나하고',\n",
       " '처녀들과',\n",
       " '생각날',\n",
       " '제발',\n",
       " '도대체',\n",
       " '길들인',\n",
       " '밀밭의',\n",
       " '하잖아',\n",
       " '맞아',\n",
       " '친구들을',\n",
       " '여기',\n",
       " '잊으면',\n",
       " '얻은',\n",
       " '.',\n",
       " '좀',\n",
       " '안녕',\n",
       " '싶지',\n",
       " '밀밭이',\n",
       " '말이야',\n",
       " '생긴다구',\n",
       " '싶은데',\n",
       " '추지',\n",
       " '될',\n",
       " '시간이',\n",
       " '여우야',\n",
       " '무척',\n",
       " '그러나',\n",
       " '색깔',\n",
       " ',',\n",
       " '그',\n",
       " '시간을',\n",
       " '하는데',\n",
       " '대해',\n",
       " '어떤',\n",
       " '중요한',\n",
       " '보이지',\n",
       " '별에도',\n",
       " '길들여진다는',\n",
       " '않았어',\n",
       " '언제까지나',\n",
       " '길들이렴',\n",
       " '돼',\n",
       " '날이지',\n",
       " '잊어버렸어',\n",
       " '눈부시게',\n",
       " '다르게',\n",
       " '뭐지',\n",
       " '나는',\n",
       " '있니',\n",
       " '뭘',\n",
       " '!',\n",
       " '놀자',\n",
       " '누구지',\n",
       " '잘못이야',\n",
       " '저',\n",
       " '이거야',\n",
       " '너하고',\n",
       " '너는',\n",
       " '있어',\n",
       " '이리',\n",
       " '무슨',\n",
       " '꽃이',\n",
       " '놀',\n",
       " '그건',\n",
       " '같아',\n",
       " '없어',\n",
       " '그거',\n",
       " '금빛',\n",
       " '저기',\n",
       " '찾고',\n",
       " '별이란',\n",
       " '밑에',\n",
       " '하나',\n",
       " '괴롭히고',\n",
       " '전혀',\n",
       " '있겠지',\n",
       " '가',\n",
       " '해야',\n",
       " '것만',\n",
       " '네가']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "def load_data_as_vocab(data_path):\n",
    "    #vocab_list = _PRE_DEFINED_ + []\n",
    "    vocab_list = []\n",
    "    with open(data_path, 'r', encoding='utf-8') as content_file:\n",
    "        for line in content_file:\n",
    "            vocab_list.append(re.findall(r\"[\\w']+\", line))\n",
    "\n",
    "    # {'_PAD_': 0, '_STA_': 1, '_EOS_': 2, '_UNK_': 3, 'Hello': 4, 'World': 5, ...}\n",
    "    #vocab_dict = {n: i for i, n in enumerate(vocab_list)}\n",
    "    #vocab_size = len(vocab_list)\n",
    "    vocabulary = list(set([item for sublist in vocab_list for item in sublist]))\n",
    "    return _PRE_DEFINED_ + vocabulary + ['.', ',' , '!', '?', '...']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0,\n",
       " 1,\n",
       " 2,\n",
       " 3,\n",
       " '싶다면',\n",
       " '제발',\n",
       " '길들여',\n",
       " '가',\n",
       " '시간과',\n",
       " '뭘',\n",
       " '친구가',\n",
       " '해',\n",
       " '나하고',\n",
       " '이리',\n",
       " '만드는',\n",
       " '나를',\n",
       " '않는다',\n",
       " '안녕',\n",
       " '미안해',\n",
       " '말이야',\n",
       " '책임이',\n",
       " '무얼',\n",
       " '거야',\n",
       " '모두',\n",
       " '나는',\n",
       " '수',\n",
       " '좀',\n",
       " '너하고',\n",
       " '친구들을',\n",
       " '시간이',\n",
       " '예쁘구나',\n",
       " '돼',\n",
       " '그래서',\n",
       " '찾고',\n",
       " '것',\n",
       " '별에도',\n",
       " '얻은',\n",
       " '시간을',\n",
       " '정말',\n",
       " '다른',\n",
       " '전혀',\n",
       " '그러구',\n",
       " '갖고',\n",
       " '내',\n",
       " '그럼',\n",
       " '생활은',\n",
       " '없지',\n",
       " '없어',\n",
       " '아니',\n",
       " '어떻게',\n",
       " '의례가',\n",
       " '밀밭의',\n",
       " '목요일은',\n",
       " '밑에',\n",
       " '아',\n",
       " '잘못이야',\n",
       " '마을',\n",
       " '네가',\n",
       " '될',\n",
       " '여기',\n",
       " '넌',\n",
       " '길들이렴',\n",
       " '진실을',\n",
       " '누구지',\n",
       " '춤을',\n",
       " '뜻이야',\n",
       " '게',\n",
       " '너는',\n",
       " '울려고',\n",
       " '그',\n",
       " '그거',\n",
       " '것만',\n",
       " '같아',\n",
       " '목요일엔',\n",
       " '울',\n",
       " '참',\n",
       " '싶은데',\n",
       " '있어야',\n",
       " '그런데',\n",
       " '색깔',\n",
       " '그들은',\n",
       " '대해',\n",
       " '하는데',\n",
       " '그래',\n",
       " '밀밭이',\n",
       " '길들여진다는',\n",
       " '친구를',\n",
       " '하잖아',\n",
       " '있으니까',\n",
       " '잘',\n",
       " '보이지',\n",
       " '도대체',\n",
       " '길들인',\n",
       " '있겠지',\n",
       " '저',\n",
       " '지겨워',\n",
       " '참을성이',\n",
       " '추지',\n",
       " '별이란',\n",
       " '대단하군',\n",
       " '밀밭을',\n",
       " '맞아',\n",
       " '무슨',\n",
       " '놀자',\n",
       " '안',\n",
       " '사냥꾼이',\n",
       " '이거야',\n",
       " '금빛',\n",
       " '중요한',\n",
       " '햇빛처럼',\n",
       " '날이지',\n",
       " '난',\n",
       " '날',\n",
       " '눈부시게',\n",
       " '생각날',\n",
       " '비밀은',\n",
       " '어떤',\n",
       " '싶지',\n",
       " '않았어',\n",
       " '잊으면',\n",
       " '사과나무',\n",
       " '위엔',\n",
       " '사람들은',\n",
       " '관계가',\n",
       " '이',\n",
       " '그건',\n",
       " '뭐지',\n",
       " '눈에',\n",
       " '무척',\n",
       " '것은',\n",
       " '저기',\n",
       " '줘',\n",
       " '잊어버렸어',\n",
       " '여우야',\n",
       " '있어',\n",
       " '거지',\n",
       " '것이',\n",
       " '놀',\n",
       " '신나는',\n",
       " '닭을',\n",
       " '꽃이',\n",
       " '해야',\n",
       " '사람들을',\n",
       " '생긴다구',\n",
       " '온갖',\n",
       " '장미한테',\n",
       " '지구',\n",
       " '다르게',\n",
       " '괴롭히고',\n",
       " '길들이면',\n",
       " '하나',\n",
       " '와서',\n",
       " '생긴다는',\n",
       " '처녀들과',\n",
       " '그럴',\n",
       " '있지',\n",
       " '네',\n",
       " '언제까지나',\n",
       " '너를',\n",
       " '그러나',\n",
       " '보면',\n",
       " '것에',\n",
       " '있니',\n",
       " '닭은',\n",
       " '.',\n",
       " ',',\n",
       " '!',\n",
       " '?',\n",
       " '...']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pp = load_data_as_vocab(data_path)\n",
    "pp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "split() takes at most 2 arguments (4 given)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-af2073ae4af9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mline\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'넌 네가 길들인 것에 대해 언제까지나 책임이 있어.'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m' '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'.'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'?'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'!'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: split() takes at most 2 arguments (4 given)"
     ]
    }
   ],
   "source": [
    "line = '넌 네가 길들인 것에 대해 언제까지나 책임이 있어.'\n",
    "line.split(' ', '.', '?', '!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['넌', '네가', '길들인', '것에', '대해', '언제까지나', '책임이', '있어']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "uu = re.findall(r\"[\\w']+\", line)\n",
    "print(uu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
